{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7a051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup paths\n",
    "CLEAN_DIR = Path('../data/badr-data/clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a45aba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 files\n",
      "\n",
      "WS_R_ch3_seq4_250523175746.csv:\n",
      "  Shape: (12062, 5)\n",
      "  Channel1: mean=690.5718, std=10.9362\n",
      "  Channel2: mean=1167.0594, std=0.2565\n",
      "  Channel3: mean=704.6077, std=13.3446\n",
      "\n",
      "WS_R_ch3_seq4_250523180012.csv:\n",
      "  Shape: (12485, 5)\n",
      "  Channel1: mean=674.1098, std=11.8944\n",
      "  Channel2: mean=1166.7730, std=0.2443\n",
      "  Channel3: mean=687.2567, std=25.1928\n",
      "\n",
      "WS_R_ch3_seq4_250523180128.csv:\n",
      "  Shape: (11070, 5)\n",
      "  Channel1: mean=672.2220, std=9.6132\n",
      "  Channel2: mean=1166.6852, std=0.2192\n",
      "  Channel3: mean=685.3770, std=15.4254\n",
      "\n",
      "WS_R_ch3_seq4_250523180233.csv:\n",
      "  Shape: (12786, 5)\n",
      "  Channel1: mean=670.7056, std=17.4000\n",
      "  Channel2: mean=1166.6600, std=0.2722\n",
      "  Channel3: mean=684.5361, std=13.1949\n",
      "\n",
      "WS_R_ch3_seq4_250523180349.csv:\n",
      "  Shape: (12438, 5)\n",
      "  Channel1: mean=668.7648, std=16.4162\n",
      "  Channel2: mean=1163.1282, std=0.2663\n",
      "  Channel3: mean=682.1575, std=12.7902\n",
      "\n",
      "WS_R_ch3_seq4_250523180502.csv:\n",
      "  Shape: (11936, 5)\n",
      "  Channel1: mean=671.4891, std=17.1172\n",
      "  Channel2: mean=1164.5004, std=0.6220\n",
      "  Channel3: mean=686.5621, std=12.1251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check mean and std for each file\n",
    "files = sorted(CLEAN_DIR.glob('*.csv'))\n",
    "print(f\"Found {len(files)} files\\n\")\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"{file.name}:\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    \n",
    "    # Get sensor columns (Channel1, Channel2, Channel3)\n",
    "    sensor_cols = [col for col in df.columns if col.startswith('Channel')]\n",
    "    \n",
    "    for col in sensor_cols:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        print(f\"  {col}: mean={mean:.4f}, std={std:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3a32f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (72777, 5)\n",
      "\n",
      "Channel1: mean=674.6097, std=16.0839\n",
      "Channel2: mean=1165.7916, std=1.5128\n",
      "Channel3: mean=688.3832, std=17.6697\n"
     ]
    }
   ],
   "source": [
    "# Combine all files\n",
    "dfs = [pd.read_csv(file) for file in files]\n",
    "df_combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Combined data shape: {df_combined.shape}\\n\")\n",
    "\n",
    "# Check mean and std of combined data\n",
    "sensor_cols = [col for col in df_combined.columns if col.startswith('Channel')]\n",
    "\n",
    "for col in sensor_cols:\n",
    "    mean = df_combined[col].mean()\n",
    "    std = df_combined[col].std()\n",
    "    print(f\"{col}: mean={mean:.4f}, std={std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d3706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before bandpass filter:\n",
      "  Channel1: mean=674.6097, std=16.0839\n",
      "  Channel2: mean=1165.7916, std=1.5128\n",
      "  Channel3: mean=688.3832, std=17.6697\n",
      "sampling rate: 1556.34 Hz\n",
      "\n",
      "After bandpass filter:\n",
      "  Channel1: mean=-16016984980640362486050418766856623797756776598800675693707796135171687648171229043284576605409133921958056754983270647872215983149918453508341760.0000, std=147375887055171797103671835638164993350423304638018030190892992614321663978420661247461521064295486864617640420096957348573572133182546618229981184.0000\n",
      "  Channel1: min=-2739049775356903989396769674223304005685106231812961667584993297593468931989804479861454925639812047487219501520539272753128495576623181496737333248.0000, max=-906638802630947316792190622058974412248106342663042626346909120222724096.0000\n",
      "  Channel2: mean=-1006479188936096686799429710121440439352637161170240562303735452277018752560139008328843074499351531611918371820444130847085576828968476518383616.0000, std=9283503618903293278993051699247236317705012846845185166197548310121093227387110316132386241775925151080717664932359983579485211757661181383278592.0000\n",
      "  Channel2: min=-172888907136708017220178995821965866164333062078582892796970130522880213358995076417621192010069908092291350500302358618185701529147844240099770368.0000, max=-48946670278558965090211949163545841896965535649733092476762639187312640.0000\n",
      "  Channel3: mean=-128738409893772511591689457811579180038841851472661733839102856594329103634917974379271373850896246428283722840364405967151258804927610485357936640.0000, std=1184980612537574162955910281834121226413147523931882452350076665109095735370827505913430847161604423485977595192999519116278530607977612396353028096.0000\n",
      "  Channel3: min=-22054426075845485485900744169792940760154288943194040226472488815339384267824712311699362901623650891945352278108807663048312794909265201554698272768.0000, max=-6130426076555452805260653172446316292291024481814587250299167489860304896.0000\n"
     ]
    }
   ],
   "source": [
    "# Test bandpass filter effect\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import config\n",
    "from preprocessing import bandpass_filter\n",
    "\n",
    "df_test = df_combined.copy()\n",
    "print(\"Before bandpass filter:\")\n",
    "for col in ['Channel1', 'Channel2', 'Channel3']:\n",
    "    print(f\"  {col}: mean={df_test[col].mean():.4f}, std={df_test[col].std():.4f}\")\n",
    "\n",
    "df_filtered = bandpass_filter(df_test)\n",
    "\n",
    "print(\"\\nAfter bandpass filter:\")\n",
    "for col in ['Channel1', 'Channel2', 'Channel3']:\n",
    "    print(f\"  {col}: mean={df_filtered[col].mean():.4f}, std={df_filtered[col].std():.4f}\")\n",
    "    print(f\"  {col}: min={df_filtered[col].min():.4f}, max={df_filtered[col].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa5e492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate: 1556.34 Hz\n",
      "Nyquist: 778.17 Hz\n",
      "Low normalized: 0.000643\n",
      "High normalized: 0.025701\n",
      "\n",
      "Filter coefficients b: [ 2.17036667e-06  0.00000000e+00 -8.68146668e-06  0.00000000e+00\n",
      "  1.30222000e-05  0.00000000e+00 -8.68146668e-06  0.00000000e+00\n",
      "  2.17036667e-06]\n",
      "Filter coefficients a: [  1.          -7.79367314  26.57733566 -51.7955525   63.09632901\n",
      " -49.19794426  23.97848466  -6.67899211   0.81401267]\n",
      "\n",
      "Poles magnitude (should be < 1 for stability): [0.97106676 0.97106676 1.00072886 1.00072886 0.99660081 0.99660081\n",
      " 0.93159862 0.93159862]\n"
     ]
    }
   ],
   "source": [
    "# Check filter design\n",
    "from scipy.signal import butter\n",
    "sampling_rate = 1556.34\n",
    "lowcut = 0.5\n",
    "highcut = 20.0\n",
    "order = 4\n",
    "\n",
    "nyquist = 0.5 * sampling_rate\n",
    "low_normalized = lowcut / nyquist\n",
    "high_normalized = highcut / nyquist\n",
    "\n",
    "print(f\"Sampling rate: {sampling_rate:.2f} Hz\")\n",
    "print(f\"Nyquist: {nyquist:.2f} Hz\")\n",
    "print(f\"Low normalized: {low_normalized:.6f}\")\n",
    "print(f\"High normalized: {high_normalized:.6f}\")\n",
    "\n",
    "b, a = butter(order, [low_normalized, high_normalized], btype='band')\n",
    "print(f\"\\nFilter coefficients b: {b}\")\n",
    "print(f\"Filter coefficients a: {a}\")\n",
    "\n",
    "# Check if filter is stable\n",
    "from numpy import roots, abs\n",
    "poles = roots(a)\n",
    "print(f\"\\nPoles magnitude (should be < 1 for stability): {abs(poles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8535e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SOS bandpass filter:\n",
      "  Channel1: mean=674.6097, std=16.0839\n",
      "  Channel2: mean=1165.7916, std=1.5128\n",
      "  Channel3: mean=688.3832, std=17.6697\n",
      "\n",
      "After SOS bandpass filter:\n",
      "  Channel1: mean=0.0199, std=6.4263\n",
      "  Channel1: min=-29.3002, max=33.8879\n",
      "  Channel2: mean=0.0008, std=0.2087\n",
      "  Channel2: min=-1.7076, max=2.0525\n",
      "  Channel3: mean=0.1243, std=7.8672\n",
      "  Channel3: min=-86.3149, max=255.7386\n"
     ]
    }
   ],
   "source": [
    "# Test with SOS (second-order sections) - more stable\n",
    "from scipy.signal import sosfiltfilt\n",
    "\n",
    "sos = butter(order, [low_normalized, high_normalized], btype='band', output='sos')\n",
    "\n",
    "df_test2 = df_combined.copy()\n",
    "print(\"Before SOS bandpass filter:\")\n",
    "for col in ['Channel1', 'Channel2', 'Channel3']:\n",
    "    print(f\"  {col}: mean={df_test2[col].mean():.4f}, std={df_test2[col].std():.4f}\")\n",
    "\n",
    "# Apply SOS filter\n",
    "for col in ['Channel1', 'Channel2', 'Channel3']:\n",
    "    df_test2[col] = sosfiltfilt(sos, df_test2[col].values)\n",
    "\n",
    "print(\"\\nAfter SOS bandpass filter:\")\n",
    "for col in ['Channel1', 'Channel2', 'Channel3']:\n",
    "    print(f\"  {col}: mean={df_test2[col].mean():.4f}, std={df_test2[col].std():.4f}\")\n",
    "    print(f\"  {col}: min={df_test2[col].min():.4f}, max={df_test2[col].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d5f556d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time differences (first 10): [0.004 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003 0.003]\n",
      "\n",
      "Mean time difference: 0.000643 seconds\n",
      "Median time difference: 0.003000 seconds\n",
      "Std of time differences: 0.388045 seconds\n",
      "\n",
      "Sampling rate (from mean): 1556.34 Hz\n",
      "Sampling rate (from median): 333.33 Hz\n",
      "\n",
      "Sampling rate (from code): 1556.34 Hz\n"
     ]
    }
   ],
   "source": [
    "# Check sampling rate calculation\n",
    "timestamps = df_combined['Timestamp'].values\n",
    "\n",
    "# Calculate time differences between consecutive samples\n",
    "time_diffs = np.diff(timestamps)\n",
    "\n",
    "print(f\"Time differences (first 10): {time_diffs[:10]}\")\n",
    "print(f\"\\nMean time difference: {time_diffs.mean():.6f} seconds\")\n",
    "print(f\"Median time difference: {np.median(time_diffs):.6f} seconds\")\n",
    "print(f\"Std of time differences: {time_diffs.std():.6f} seconds\")\n",
    "\n",
    "# Sampling rate = 1 / mean_time_diff\n",
    "sampling_rate_correct = 1.0 / time_diffs.mean()\n",
    "sampling_rate_median = 1.0 / np.median(time_diffs)\n",
    "\n",
    "print(f\"\\nSampling rate (from mean): {sampling_rate_correct:.2f} Hz\")\n",
    "print(f\"Sampling rate (from median): {sampling_rate_median:.2f} Hz\")\n",
    "\n",
    "# Check what the preprocessing code calculates\n",
    "from preprocessing import _calculate_sampling_rate\n",
    "sampling_rate_code = _calculate_sampling_rate(df_combined['Timestamp'])\n",
    "print(f\"\\nSampling rate (from code): {sampling_rate_code:.2f} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c11f526a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min time diff: -48.594000 seconds\n",
      "Max time diff: 1.187000 seconds\n",
      "25th percentile: 0.003000 seconds\n",
      "75th percentile: 0.003000 seconds\n",
      "99th percentile: 0.004000 seconds\n",
      "\n",
      "Normal samples (~0.003s): 71926 (98.83%)\n",
      "Outliers: 850 (1.17%)\n",
      "\n",
      "Large gaps (>1s): 5\n",
      "Max gap: 1.19 seconds\n",
      "Gap locations (first 5): [51102 53035 61620 63404 67145]\n"
     ]
    }
   ],
   "source": [
    "# Investigate the time difference distribution\n",
    "print(f\"Min time diff: {time_diffs.min():.6f} seconds\")\n",
    "print(f\"Max time diff: {time_diffs.max():.6f} seconds\")\n",
    "print(f\"25th percentile: {np.percentile(time_diffs, 25):.6f} seconds\")\n",
    "print(f\"75th percentile: {np.percentile(time_diffs, 75):.6f} seconds\")\n",
    "print(f\"99th percentile: {np.percentile(time_diffs, 99):.6f} seconds\")\n",
    "\n",
    "# Count how many are close to 0.003 (normal) vs outliers\n",
    "normal_samples = np.sum((time_diffs >= 0.002) & (time_diffs <= 0.004))\n",
    "outliers = np.sum((time_diffs < 0.002) | (time_diffs > 0.004))\n",
    "print(f\"\\nNormal samples (~0.003s): {normal_samples} ({100*normal_samples/len(time_diffs):.2f}%)\")\n",
    "print(f\"Outliers: {outliers} ({100*outliers/len(time_diffs):.2f}%)\")\n",
    "\n",
    "# Where are the large gaps?\n",
    "large_gaps = time_diffs > 1.0  # gaps > 1 second\n",
    "print(f\"\\nLarge gaps (>1s): {np.sum(large_gaps)}\")\n",
    "if np.sum(large_gaps) > 0:\n",
    "    print(f\"Max gap: {time_diffs.max():.2f} seconds\")\n",
    "    gap_indices = np.where(large_gaps)[0]\n",
    "    print(f\"Gap locations (first 5): {gap_indices[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the requested file and inspect data around row 51102\n",
    "PREPROC_DIR = Path('../data/badr-data/proc')\n",
    "\n",
    "df_check = pd.read_csv(PREPROC_DIR / 'WS_R_ch3_seq4.csv')\n",
    "\n",
    "row_idx = 51102\n",
    "\n",
    "\n",
    "df_check.iloc[row_idx - 10: row_idx + 10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
